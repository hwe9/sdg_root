/sdg_root/src/api

-- database.py

import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import StaticPool
import logging

logger = logging.getLogger(__name__)

DATABASE_URL = os.environ.get("DATABASE_URL")

if not DATABASE_URL:
    # Fallback for development
    DATABASE_URL = "postgresql://postgres:postgres@localhost:5432/sdg_pipeline"
    logger.warning("DATABASE_URL not set, using default development database")

def get_db_url():
    """Get database URL for external usage"""
    return DATABASE_URL

engine_kwargs = {
    "pool_pre_ping": True,
    "pool_recycle": 300,
    "pool_size": 10,
    "max_overflow": 20
}

if DATABASE_URL.startswith("sqlite"):
    engine_kwargs.update({
        "poolclass": StaticPool,
        "connect_args": {"check_same_thread": False}
    })

engine = create_engine(DATABASE_URL, **engine_kwargs)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def get_db():
    """Database session dependency with proper error handling"""
    db = SessionLocal()
    try:
        yield db
    except Exception as e:
        logger.error(f"Database session error: {e}")
        db.rollback()
        raise
    finally:
        db.close()

def check_database_health():
    """Check if database is accessible"""
    try:
        with engine.connect() as conn:
            conn.execute("SELECT 1")
        return True
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        return False
        
-- Dockerfile

FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    postgresql-client \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 apiuser && chown -R apiuser:apiuser /app
USER apiuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run the application
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

-- main.py

from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List
import models, schemas
from database import get_db

app = FastAPI()

def read_root():
    return {"message": "API Service is running!"}

# --- CRUD Endpunkte für Articles ---

@app.post("/articles/", response_model=schemas.Article)
def create_article(article: schemas.ArticleCreate, db: Session = Depends(get_db)):
    db_article = models.Article(**article.dict())
    db.add(db_article)
    db.commit()
    db.refresh(db_article)
    return db_article

@app.get("/articles/", response_model=List[schemas.Article])
def read_articles(db: Session = Depends(get_db)):
    articles = db.query(models.Article).all()
    return articles

@app.get("/articles/{article_id}", response_model=schemas.Article)
def read_article(article_id: int, db: Session = Depends(get_db)):
    db_article = db.query(models.Article).filter(models.Article.id == article_id).first()
    if db_article is None:
        raise HTTPException(status_code=404, detail="Article not found")
    return db_article

@app.get("/articles/{article_id}/chunks")
async def get_article_chunks(
    article_id: int, 
    sdg_filter: Optional[str] = None,
    limit: int = 10,
    db: Session = Depends(get_db)
):
    article = db.query(models.Article).filter(models.Article.id == article_id).first()
    if not article:
        raise HTTPException(status_code=404, detail="Article not found")
    

    query = db.query(models.ArticleChunk).filter(models.ArticleChunk.article_id == article_id)
    
    if sdg_filter:
        query = query.filter(models.ArticleChunk.sdg_section == sdg_filter)
    
    chunks = query.order_by(models.ArticleChunk.chunk_order).limit(limit).all()
    
    return {
        "article_id": article_id,
        "total_chunks": len(chunks),
        "chunks": chunks
    }

@app.get("/search/sdg/{sdg_id}/chunks")
async def search_chunks_by_sdg(
    sdg_id: int,
    query: Optional[str] = None,
    limit: int = 5,
    db: Session = Depends(get_db)
):
    sdg = db.query(models.Sdg).filter(models.Sdg.id == sdg_id).first()
    if not sdg:
        raise HTTPException(status_code=404, detail="SDG not found")
    
    chunks_query = db.query(models.ArticleChunk).join(models.Article).filter(
        models.Article.sdg_id == sdg_id
    )
    
    if query:
        chunks_query = chunks_query.filter(models.ArticleChunk.text.contains(query))
    
    chunks = chunks_query.limit(limit).all()
    
    return {
        "sdg_id": sdg_id,
        "sdg_name": sdg.name,
        "query": query,
        "results": chunks
    }

@app.get("/articles/{article_id}/summary")
async def get_article_summary(
    article_id: int,
    max_chunks: int = 5,
    db: Session = Depends(get_db)
):
    article = db.query(models.Article).filter(models.Article.id == article_id).first()
    if not article:
        raise HTTPException(status_code=404, detail="Article not found")
    
    # Get most relevant chunks (ordered by importance/SDG relevance)
    chunks = db.query(models.ArticleChunk).filter(
        models.ArticleChunk.article_id == article_id
    ).order_by(models.ArticleChunk.chunk_order).limit(max_chunks).all()
    
    if not chunks:
        raise HTTPException(status_code=404, detail="No chunks found for article")
    
    # Generate summary from chunks
    summary_text = " ".join([chunk.text[:200] + "..." for chunk in chunks])
    
    # Extract SDG information
    sdg_sections = list(set([chunk.sdg_section for chunk in chunks if chunk.sdg_section]))
    
    return {
        "article_id": article_id,
        "article_title": article.title,
        "summary": summary_text,
        "sdg_sections": sdg_sections,
        "chunk_count": len(chunks),
        "generated_at": "2025-08-22T15:29:00Z"
    }

@app.post("/images/", response_model=schemas.ImageBase)
def create_image(image: schemas.ImageBase, db: Session = Depends(get_db)):
    db_image = models.Image(**image.dict())
    db.add(db_image)
    db.commit()
    db.refresh(db_image)
    return db_image

@app.get("/images/{article_id}", response_model=List[schemas.ImageBase])
def get_images(article_id: int, db: Session = Depends(get_db)):
    images = db.query(models.Image).filter(models.Image.article_id == article_id).all()
    return images

# --- CRUD Endpunkte für SDGs ---

@app.post("/sdgs/", response_model=schemas.Sdg)
def create_sdg(sdg: schemas.SdgCreate, db: Session = Depends(get_db)):
    db_sdg = models.Sdg(**sdg.dict())
    db.add(db_sdg)
    db.commit()
    db.refresh(db_sdg)
    return db_sdg

@app.get("/sdgs/", response_model=List[schemas.Sdg])
def read_sdgs(db: Session = Depends(get_db)):
    sdgs = db.query(models.Sdg).all()
    return sdgs

# --- CRUD Endpunkte für Actors ---

@app.post("/actors/", response_model=schemas.Actor)
def create_actor(actor: schemas.ActorCreate, db: Session = Depends(get_db)):
    db_actor = models.Actor(**actor.dict())
    db.add(db_actor)
    db.commit()
    db.refresh(db_actor)
    return db_actor

@app.get("/actors/", response_model=List[schemas.Actor])
def read_actors(db: Session = Depends(get_db)):
    actors = db.query(models.Actor).all()
    return actors

        
-- migrate_existing_schema.py

"""
Migration script to enhance existing schema without breaking changes
"""
import logging
from sqlalchemy import create_engine, text, inspect, MetaData, Table, Column, String, Integer, Float, Boolean, DateTime, JSON
from sqlalchemy.sql import func
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DATABASE_URL = os.environ.get("DATABASE_URL")
engine = create_engine(DATABASE_URL)

def migrate_existing_schema():

    logger.info("Starting schema migration...")
    
    with engine.begin() as conn:
        
        try:
            conn.execute(text("""
                ALTER TABLE sdgs 
                ADD COLUMN IF NOT EXISTS goal_number INTEGER,
                ADD COLUMN IF NOT EXISTS name_de VARCHAR,
                ADD COLUMN IF NOT EXISTS name_fr VARCHAR,
                ADD COLUMN IF NOT EXISTS name_es VARCHAR,
                ADD COLUMN IF NOT EXISTS name_zh VARCHAR,
                ADD COLUMN IF NOT EXISTS name_hi VARCHAR,
                ADD COLUMN IF NOT EXISTS description_de TEXT,
                ADD COLUMN IF NOT EXISTS description_fr TEXT,
                ADD COLUMN IF NOT EXISTS description_es TEXT,
                ADD COLUMN IF NOT EXISTS description_zh TEXT,
                ADD COLUMN IF NOT EXISTS description_hi TEXT,
                ADD COLUMN IF NOT EXISTS color_hex VARCHAR(7),
                ADD COLUMN IF NOT EXISTS icon_url VARCHAR(500),
                ADD COLUMN IF NOT EXISTS priority_weight FLOAT DEFAULT 1.0,
                ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP WITH TIME ZONE
            """))
            logger.info("✅ Enhanced SDGs table")
        except Exception as e:
            logger.warning(f"SDGs table enhancement: {e}")

        try:
            conn.execute(text("""
                ALTER TABLE articles 
                ADD COLUMN IF NOT EXISTS summary TEXT,
                ADD COLUMN IF NOT EXISTS sdg_confidence FLOAT DEFAULT 0.0,
                ADD COLUMN IF NOT EXISTS publication_date TIMESTAMP WITH TIME ZONE,
                ADD COLUMN IF NOT EXISTS country_code VARCHAR(3),
                ADD COLUMN IF NOT EXISTS language VARCHAR(5) DEFAULT 'en',
                ADD COLUMN IF NOT EXISTS word_count INTEGER,
                ADD COLUMN IF NOT EXISTS readability_score FLOAT,
                ADD COLUMN IF NOT EXISTS content_quality_score FLOAT DEFAULT 0.0,
                ADD COLUMN IF NOT EXISTS has_embeddings BOOLEAN DEFAULT FALSE,
                ADD COLUMN IF NOT EXISTS embedding_model VARCHAR(100),
                ADD COLUMN IF NOT EXISTS embedding_dimension INTEGER,
                ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP WITH TIME ZONE,
                ADD COLUMN IF NOT EXISTS processed_at TIMESTAMP WITH TIME ZONE
            """))
            logger.info("✅ Enhanced Articles table")
        except Exception as e:
            logger.warning(f"Articles table enhancement: {e}")

        try:
            conn.execute(text("""
                ALTER TABLE article_chunks 
                ADD COLUMN IF NOT EXISTS chunk_order INTEGER,
                ADD COLUMN IF NOT EXISTS sdg_relevance_scores JSON,
                ADD COLUMN IF NOT EXISTS confidence_score FLOAT DEFAULT 0.0,
                ADD COLUMN IF NOT EXISTS has_embedding BOOLEAN DEFAULT FALSE,
                ADD COLUMN IF NOT EXISTS embedding_hash VARCHAR(64)
            """))
            logger.info("✅ Enhanced ArticleChunks table")
        except Exception as e:
            logger.warning(f"ArticleChunks table enhancement: {e}")

        try:
            conn.execute(text("""
                ALTER TABLE actors 
                ADD COLUMN IF NOT EXISTS region VARCHAR(100),
                ADD COLUMN IF NOT EXISTS is_active BOOLEAN DEFAULT TRUE,
                ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            """))
            logger.info("✅ Enhanced Actors table")
        except Exception as e:
            logger.warning(f"Actors table enhancement: {e}")

        
        try:
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS sdg_interlinkages (
                    id SERIAL PRIMARY KEY,
                    from_sdg_id INTEGER REFERENCES sdgs(id),
                    to_sdg_id INTEGER REFERENCES sdgs(id),
                    relationship_type VARCHAR(50) NOT NULL,
                    strength FLOAT NOT NULL CHECK (strength >= 0.0 AND strength <= 1.0),
                    evidence_level VARCHAR(20) DEFAULT 'medium',
                    source VARCHAR(200),
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                )
            """))
            logger.info("✅ Created SDG Interlinkages table")
        except Exception as e:
            logger.warning(f"SDG Interlinkages table creation: {e}")

        
        try:
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS articles_sdg_targets (
                    article_id INTEGER REFERENCES articles(id) ON DELETE CASCADE,
                    sdg_id INTEGER REFERENCES sdgs(id) ON DELETE CASCADE,
                    confidence_score FLOAT DEFAULT 0.0,
                    PRIMARY KEY (article_id, sdg_id)
                )
            """))
            logger.info("✅ Created Articles-SDGs many-to-many table")
        except Exception as e:
            logger.warning(f"Articles-SDGs table creation: {e}")

        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_articles_sdg_id ON articles(sdg_id)",
            "CREATE INDEX IF NOT EXISTS idx_articles_region ON articles(region)",
            "CREATE INDEX IF NOT EXISTS idx_articles_publication_year ON articles(publication_year)",
            "CREATE INDEX IF NOT EXISTS idx_articles_language ON articles(language)",
            "CREATE INDEX IF NOT EXISTS idx_articles_has_embeddings ON articles(has_embeddings)",
            "CREATE INDEX IF NOT EXISTS idx_sdg_progress_year ON sdg_progress(year)",
            "CREATE INDEX IF NOT EXISTS idx_chunks_article_order ON article_chunks(article_id, chunk_order)",
            "CREATE INDEX IF NOT EXISTS idx_sdgs_goal_number ON sdgs(goal_number)"
        ]
        
        for index_sql in indexes:
            try:
                conn.execute(text(index_sql))
            except Exception as e:
                logger.warning(f"Index creation: {e}")
        
        logger.info("✅ Created performance indexes")

        try:
            sdg_updates = [
                ("No Poverty", 1, "#E5243B"),
                ("Zero Hunger", 2, "#DDA63A"),
                ("Good Health and Well-being", 3, "#4C9F38"),
                ("Quality Education", 4, "#C5192D"),
                ("Gender Equality", 5, "#FF3A21"),
                ("Clean Water and Sanitation", 6, "#26BDE2"),
                ("Affordable and Clean Energy", 7, "#FCC30B"),
                ("Decent Work and Economic Growth", 8, "#A21942"),
                ("Industry, Innovation and Infrastructure", 9, "#FD6925"),
                ("Reduced Inequalities", 10, "#DD1367"),
                ("Sustainable Cities and Communities", 11, "#FD9D24"),
                ("Responsible Consumption and Production", 12, "#BF8B2E"),
                ("Climate Action", 13, "#3F7E44"),
                ("Life Below Water", 14, "#0A97D9"),
                ("Life on Land", 15, "#56C02B"),
                ("Peace, Justice and Strong Institutions", 16, "#00689D"),
                ("Partnerships for the Goals", 17, "#19486A")
            ]
            
            for name, goal_number, color in sdg_updates:
                conn.execute(text("""
                    UPDATE sdgs 
                    SET goal_number = :goal_number, color_hex = :color
                    WHERE name ILIKE :name AND goal_number IS NULL
                """), {"name": f"%{name}%", "goal_number": goal_number, "color": color})
            
            logger.info("✅ Updated existing SDG data")
        except Exception as e:
            logger.warning(f"SDG data update: {e}")
        
            conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS sdg_targets (
                        target_id VARCHAR(10) PRIMARY KEY,
                        goal_id INTEGER REFERENCES sdgs(id) ON DELETE CASCADE,
                        title_en TEXT NOT NULL,
                        title_de TEXT,
                        title_fr TEXT,
                        title_es TEXT,
                        title_zh TEXT,
                        title_hi TEXT,
                        description TEXT,
                        description_de TEXT,
                        description_fr TEXT,
                        description_es TEXT,
                        description_zh TEXT,
                        description_hi TEXT,
                        target_type VARCHAR(50),
                        deadline_year INTEGER DEFAULT 2030,
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        updated_at TIMESTAMP WITH TIME ZONE
                    );
                """))
                

            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS sdg_indicators (
                    indicator_id VARCHAR(20) PRIMARY KEY,
                    target_id VARCHAR(10) REFERENCES sdg_targets(target_id) ON DELETE CASCADE,
                    title_en TEXT NOT NULL,
                    title_de TEXT,
                    title_fr TEXT,
                    title_es TEXT,
                    title_zh TEXT,
                    title_hi TEXT,
                    unit_of_measurement TEXT,
                    data_source TEXT,
                    methodology TEXT,
                    tier_classification VARCHAR(10),
                    custodian_agency TEXT,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    updated_at TIMESTAMP WITH TIME ZONE
                );
            """))
            
            # Create indexes
            conn.execute(text("CREATE INDEX IF NOT EXISTS idx_sdg_targets_goal_id ON sdg_targets(goal_id);"))
            conn.execute(text("CREATE INDEX IF NOT EXISTS idx_sdg_indicators_target_id ON sdg_indicators(target_id);"))
                
            logger.info("✅ Created SDG targets and indicators tables")
            
        except Exception as e:
            logger.error(f"Error creating SDG targets/indicators: {e}")

    logger.info("Schema migration completed successfully!")



if __name__ == "__main__":
    migrate_existing_schema()


-- models.py

import os

from sqlalchemy import create_engine, Column, Integer, String, Text, Float, ForeignKey, DateTime, Table, JSON, Boolean

from sqlalchemy.orm import relationship, sessionmaker, declarative_base

from sqlalchemy.sql import func

from datetime import datetime

DATABASE_URL = os.environ.get("DATABASE_URL")

engine = create_engine(DATABASE_URL, pool_pre_ping=True)

Base = declarative_base()


articles_tags = Table(
    'articles_tags',
    Base.metadata,
    Column('article_id', Integer, ForeignKey('articles.id')),
    Column('tag_id', Integer, ForeignKey('tags.id'))
)


articles_ai_topics = Table(
    'articles_ai_topics',
    Base.metadata,
    Column('article_id', Integer, ForeignKey('articles.id')),
    Column('ai_topic_id', Integer, ForeignKey('ai_topics.id'))
)

articles_sdg_targets = Table(
    'articles_sdg_targets',
    Base.metadata,
    Column('article_id', Integer, ForeignKey('articles.id'), primary_key=True),
    Column('sdg_id', Integer, ForeignKey('sdgs.id'), primary_key=True),
    Column('confidence_score', Float, default=0.0)
)

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True)
    hashed_password = Column(String)

class Sdg(Base):
    __tablename__ = "sdgs"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, unique=True, index=True)
    name_de = Column(String)  
    name_fr = Column(String)  
    name_es = Column(String)  
    name_zh = Column(String)  
    name_hi = Column(String)
    description = Column(Text)
    description_de = Column(Text) 
    description_fr = Column(Text)
    description_es = Column(Text)
    description_zh = Column(Text)
    description_hi = Column(Text)
    color_hex = Column(String(7))  
    icon_url = Column(String(500)) 
    priority_weight = Column(Float, default=1.0) 
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    progress = relationship("SdgProgress", back_populates="sdg")
    articles_multi = relationship("Article", secondary=articles_sdg_targets, back_populates="sdgs_multi")
class SDGTarget(Base):
    __tablename__ = "sdg_targets"
    target_id = Column(String(10), primary_key=True)  # "1.1", "1.2", etc.
    goal_id = Column(Integer, ForeignKey("sdgs.id"))
    title_en = Column(Text, nullable=False)
    title_de = Column(Text)
    title_fr = Column(Text)
    title_es = Column(Text)
    title_zh = Column(Text)
    title_hi = Column(Text)

    description = Column(Text)
    description_de = Column(Text)
    description_fr = Column(Text)
    description_es = Column(Text)
    description_zh = Column(Text)
    description_hi = Column(Text)

    target_type = Column(String(50)) 
    deadline_year = Column(Integer, default=2030)
    
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    # Relationships
    goal = relationship("Sdg", back_populates="targets")
    indicators = relationship("SDGIndicator", back_populates="target")
class SDGIndicator(Base):
    __tablename__ = "sdg_indicators"
    indicator_id = Column(String(20), primary_key=True)
    target_id = Column(String(10), ForeignKey("sdg_targets.target_id"))
    title_en = Column(Text, nullable=False)
    title_de = Column(Text)
    title_fr = Column(Text)
    title_es = Column(Text)
    title_zh = Column(Text)
    title_hi = Column(Text)
    
    unit_of_measurement = Column(Text)
    data_source = Column(Text)
    methodology = Column(Text)
    tier_classification = Column(String(10))
    custodian_agency = Column(Text)
    
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())

    target = relationship("SDGTarget", back_populates="indicators")


class Actor(Base):
    __tablename__ = "actors"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, unique=True, index=True)
    type = Column(String)
    country_code = Column(String(3), index=True) 
    region = Column(String(100), index=True) 
    is_active = Column(Boolean, default=True) 
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    progress = relationship("SdgProgress", back_populates="actor")

class AiTopic(Base):
    __tablename__ = "ai_topics"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, unique=True, index=True)
    description = Column(Text) 
    category = Column(String(100), index=True) 
    sdg_relevance = Column(JSON) 
    maturity_level = Column(String(50)) 
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    articles = relationship("Article", secondary=articles_ai_topics, back_populates="ai_topics")

class Article(Base):
    __tablename__ = "articles"
    id = Column(Integer, primary_key=True, index=True)
    title = Column(String, index=True)
    content_original = Column(Text)
    content_english = Column(Text)
    summary = Column(Text)
    keywords = Column(Text)
    sdg_id = Column(Integer, ForeignKey("sdgs.id"), index=True)
    sdg_confidence = Column(Float, default=0.0)
    
    authors = Column(Text)
    publication_year = Column(Integer)
    publication_date = Column(DateTime(timezone=True), index=True)
    publisher = Column(String)
    doi = Column(String, unique=True)
    isbn = Column(String, unique=True)
    region = Column(Text(100), index=True)
    country_code = Column(String(3), index=True) 
    language = Column(String(5), default="en", index=True) 
    
    context = Column(String)
    study_type = Column(String, index=True)
    research_methods = Column(String)
    data_sources = Column(String)
    funding = Column(Text)
    funding_info = Column(String)
    bias_indicators = Column(String)
    abstract_original = Column(Text)
    abstract_english = Column(Text)
    relevance_questions = Column(String)
    source_url = Column(String(2000), unique=True, index=True)
    availability = Column(String)
    
    citation_count = Column(Integer, default=0)
    impact_metrics = Column(JSON)
    impact_factor = Column(Float)
    policy_impact = Column(String)

    has_embeddings = Column(Boolean, default=False, index=True)
    embedding_model = Column(String(100))
    embedding_dimension = Column(Integer)
    
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    processed_at = Column(DateTime(timezone=True))
    
    tags = relationship("Tag", secondary=articles_tags, back_populates="articles")
    ai_topics = relationship("AiTopic", secondary=articles_ai_topics, back_populates="articles")
    image_paths = relationship("Image", back_populates="article")
    chunks = relationship("ArticleChunk", back_populates="article", cascade="all, delete-orphan")
    sdgs_multi = relationship("Sdg", secondary=articles_sdg_targets, back_populates="articles_multi")
    primary_sdg = relationship("Sdg", foreign_keys=[sdg_id])


class ArticleChunk(Base):
    __tablename__ = "article_chunks"
    id = Column(Integer, primary_key=True, index=True, index=True)
    article_id = Column(Integer, ForeignKey("articles.id"))
    chunk_id = Column(Integer)
    chunk_order = Column(Integer, index=True)
    text = Column(Text)
    chunk_length = Column(Integer)
    sdg_section = Column(String, index=True)
    sub_section_id = Column(Integer)
    sdg_relevance_scores = Column(JSON) 
    confidence_score = Column(Float, default=0.0)
    has_embedding = Column(Boolean, default=False)
    embedding_hash = Column(String(64))
    created_at = Column(DateTime, default=datetime.utcnow)
    article = relationship("Article", back_populates="chunks")

class SdgProgress(Base):
    __tablename__ = "sdg_progress"
    id = Column(Integer, primary_key=True, index=True)
    actor_id = Column(Integer, ForeignKey("actors.id"), index=True)
    sdg_id = Column(Integer, ForeignKey("sdgs.id"), index=True)
    score = Column(Float)
    year = Column(Integer)
    progress_status = Column(String(50)) 
    trend_direction = Column(String(20)) 
    data_quality = Column(String(20), default="medium") 
    data_sources = Column(JSON) 
    confidence_level = Column(Float, default=0.5) 
    
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    actor = relationship("Actor", back_populates="progress")
    sdg = relationship("Sdg", back_populates="progress")

class Tag(Base):
    __tablename__ = "tags"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, unique=True, index=True)
    category = Column(String(100), index=True) 
    usage_count = Column(Integer, default=0)
    articles = relationship("Article", secondary=articles_tags, back_populates="articles")


class Image(Base):
    __tablename__ = "images"
    id = Column(Integer, primary_key=True, index=True)
    article_id = Column(Integer, ForeignKey('articles.id'), index=True)
    original_path = Column(String(500))
    ocr_text = Column(Text)
    page = Column(Integer)
    caption = Column(Text)
    sdg_tags = Column(JSON)
    ai_tags = Column(Text)
    image_type = Column(String)
    file_size = Column(Integer)
    width = Column(Integer)
    height = Column(Integer)
    format = Column(String(10))
    processed_at = Column(DateTime(timezone=True))
    article = relationship("Article", back_populates="image_paths")

class SdgInterlinkage(Base):
    """SDG goal interlinkages"""
    __tablename__ = "sdg_interlinkages"
    
    id = Column(Integer, primary_key=True, index=True)
    from_sdg_id = Column(Integer, ForeignKey("sdgs.id"), index=True)
    to_sdg_id = Column(Integer, ForeignKey("sdgs.id"), index=True)
    relationship_type = Column(String(50)) 
    strength = Column(Float, nullable=False) 
    evidence_level = Column(String(20), default="medium")
    source = Column(String(200))
    
    from_sdg = relationship("Sdg", foreign_keys=[from_sdg_id])
    to_sdg = relationship("Sdg", foreign_keys=[to_sdg_id])


Index('idx_articles_sdg_region_year', Article.sdg_id, Article.region, Article.publication_year)
Index('idx_articles_language_quality', Article.language, Article.content_quality_score)
Index('idx_articles_has_embeddings', Article.has_embeddings)
Index('idx_chunks_article_order', ArticleChunk.article_id, ArticleChunk.chunk_order)
Index('idx_progress_actor_sdg_year', SdgProgress.actor_id, SdgProgress.sdg_id, SdgProgress.year)

Base.metadata.create_all(bind=engine)


-- schemas.py

from pydantic import BaseModel
from datetime import datetime
from typing import Optional, List

class AiTopicBase(BaseModel):
    name: str

class AiTopicCreate(AiTopicBase):
    pass

class AiTopic(AiTopicBase):
    id: int

    class Config:
        from_attributes = True

class TagBase(BaseModel):
    name: str

class TagCreate(TagBase):
    pass

class Tag(TagBase):
    id: int

    class Config:
        from_attributes = True

class SdgBase(BaseModel):
    name: str
    description: str

class SdgCreate(SdgBase):
    pass

class Sdg(SdgBase):
    id: int

    class Config:
        from_attributes = True

class ActorBase(BaseModel):
    name: str
    type: str
    country_code: Optional[str] = None

class ActorCreate(ActorBase):
    pass

class Actor(ActorBase):
    id: int

    class Config:
        from_attributes = True

class SdgProgressBase(BaseModel):
    actor_id: int
    sdg_id: int
    score: float
    year: int

class SdgProgress(SdgProgressBase):
    id: int

    class Config:
        from_attributes = True

class ArticleBase(BaseModel):
    title: str
    content_original: Optional[str]
    content_english: Optional[str]
    keywords: Optional[str]
    sdg_id: Optional[int]
    authors: Optional[str]
    publication_year: Optional[int]
    publisher: Optional[str]
    doi: Optional[str]
    isbn: Optional[str]
    region: Optional[str]
    context: Optional[str]
    study_type: Optional[str]
    research_methods: Optional[str]
    data_sources: Optional[str]
    funding: Optional[str]
    funding_info: Optional[str]
    bias_indicators: Optional[str]
    abstract_original: Optional[str]
    abstract_english: Optional[str]
    relevance_questions: Optional[str]
    source_url: Optional[str]
    availability: Optional[str]
    citation_count: Optional[int]
    impact_metrics: Optional[dict]
    impact_factor: Optional[float]
    policy_impact: Optional[str]
    tags: Optional[List[str]] = []
    ai_topics: Optional[List[str]] = []

class ImageBase(BaseModel):
    article_id: int
    original_path: str
    ocr_text: Optional[str]
    page: Optional[int]
    caption: Optional[str]
    sdg_tags: Optional[dict]
    ai_tags: Optional[str]
    image_type: Optional[str]

class ArticleCreate(ArticleBase):
    pass

class Article(ArticleBase):
    id: int
    created_at: datetime
    tags: List[Tag] = []
    ai_topics: List[AiTopic] = []

class ArticleChunkBase(BaseModel):
    chunk_order: int
    text: str
    chunk_length: Optional[int] = None
    sdg_section: Optional[str] = None
    confidence_score: Optional[float] = 0.0

class ArticleChunkCreate(ArticleChunkBase):
    article_id: int

class ArticleChunk(ArticleChunkBase):
    id: int
    article_id: int
    created_at: datetime
    
    class Config:
        from_attributes = True

class Article(ArticleBase):
    id: int
    created_at: datetime
    tags: List[Tag] = []
    ai_topics: List[AiTopic] = []
    chunks: List[ArticleChunk] = []  # NEW LINE
    
class SDGTargetBase(BaseModel):
    target_id: str
    goal_id: int
    title_en: str
    title_de: Optional[str] = None
    title_fr: Optional[str] = None
    title_es: Optional[str] = None
    title_zh: Optional[str] = None
    title_hi: Optional[str] = None

class SDGTargetCreate(SDGTargetBase):
    pass

class SDGTarget(SDGTargetBase):
    created_at: datetime
    updated_at: Optional[datetime] = None
    
    class Config:
        from_attributes = True

class SDGIndicatorBase(BaseModel):
    indicator_id: str
    target_id: str
    title_en: str
    title_de: Optional[str] = None
    title_fr: Optional[str] = None
    title_es: Optional[str] = None
    title_zh: Optional[str] = None
    title_hi: Optional[str] = None

class SDGIndicator(SDGIndicatorBase):
    created_at: datetime
    
class Config:
    from_attributes = True



-- requirement.txt

fastapi
uvicorn[standard]
python-dotenv
pydantic
sqlalchemy[asyncio]
psycopg2-binaryfastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0
pydantic==2.5.0
sqlalchemy[asyncio]==2.0.23
psycopg2-binary==2.9.7
alembic==1.13.1
redis==5.0.1
celery==5.3.4
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dateutil==2.8.2
